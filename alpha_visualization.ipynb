{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visualizing the model  \n",
    "This notebook is meant as an example for how to create visualizations\n",
    "like the ones provided in the appendix.\n",
    "\n",
    "It is expected that this might need some slight modification depending on the user's \n",
    "setup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Quadro K2200\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from theano import tensor\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pkl\n",
    "import numpy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import skimage\n",
    "import skimage.transform\n",
    "import skimage.io\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/flipvanrijn/Workspace/Dedicon-Thesis/networks/arctic-captions/')\n",
    "\n",
    "import capgen\n",
    "import generate_caps as gencaps\n",
    "import flickr8k\n",
    "import flickr30k\n",
    "import coco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model and dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: coco\n"
     ]
    }
   ],
   "source": [
    "datasets = {'flickr8k': (flickr8k.load_data, flickr8k.prepare_data),\n",
    "             'flickr30k': (flickr30k.load_data, flickr30k.prepare_data),\n",
    "             'coco': (coco.load_data, coco.prepare_data)}\n",
    "\n",
    "# location of the model file, the pkl file should be named \"model_name.npz.pkl\"\n",
    "model= 'first_run.npz'\n",
    "pkl_file = 'first_run.npz.pkl'\n",
    "# location of the devset split file like the ones in /splits\n",
    "dev_list = './splits/coco_train.txt' \n",
    "image_path = '/media/Data/flipvanrijn/datasets/coco/images/val/'\n",
    "model_path = '/media/Data/flipvanrijn/models/'\n",
    "\n",
    "# load model model_options\n",
    "with open(model_path+pkl_file, 'rb') as f:\n",
    "    options = pkl.load(f)\n",
    "\n",
    "print 'Loading: ' + options['dataset']\n",
    "\n",
    "flist = []\n",
    "with open(dev_list, 'r') as f:\n",
    "    for l in f:\n",
    "        flist.append(l.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep aspect ratio, and center crop\n",
    "def LoadImage(file_name, resize=256, crop=224):\n",
    "    image = Image.open(file_name)\n",
    "    width, height = image.size\n",
    "\n",
    "    if width > height:\n",
    "        width = (width * resize) / height\n",
    "        height = resize\n",
    "    else:\n",
    "        height = (height * resize) / width\n",
    "        width = resize\n",
    "    left = (width  - crop) / 2\n",
    "    top  = (height - crop) / 2\n",
    "    image_resized = image.resize((width, height), Image.BICUBIC).crop((left, top, left + crop, top + crop))\n",
    "    data = numpy.array(image_resized.convert('RGB').getdata()).reshape(crop, crop, 3)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "    load_data, prepare_data = datasets[options['dataset']]\n",
    "\n",
    "    train, valid, test, worddict = load_data(False, True, False)\n",
    "    print 'Data loaded'\n",
    "\n",
    "    word_idict = dict()\n",
    "    for kk, vv in worddict.iteritems():\n",
    "        word_idict[vv] = kk\n",
    "    word_idict[0] = '<eos>'\n",
    "    word_idict[1] = 'UNK'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Theano Graph  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building f_init... Done\n"
     ]
    }
   ],
   "source": [
    "    # build the sampling functions and model\n",
    "    trng = RandomStreams(1234)\n",
    "    use_noise = theano.shared(numpy.float32(0.), name='use_noise')\n",
    "\n",
    "    params = capgen.init_params(options)\n",
    "    params = capgen.load_params(model_path+model, params)\n",
    "    tparams = capgen.init_tparams(params)\n",
    "\n",
    "    # word index\n",
    "    f_init, f_next = capgen.build_sampler(tparams, options, use_noise, trng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    trng, use_noise, \\\n",
    "          inps, alphas, alphas_samples, \\\n",
    "          cost, opt_outs = \\\n",
    "          capgen.build_model(tparams, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/theano/scan_module/scan_perform_ext.py:133: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    }
   ],
   "source": [
    "# get the alphas and selector value [called \\beta in the paper]\n",
    "\n",
    "# create update rules for the stochastic attention\n",
    "hard_attn_updates = []\n",
    "if options['attn_type'] == 'stochastic':\n",
    "    baseline_time = theano.shared(numpy.float32(0.), name='baseline_time')\n",
    "    hard_attn_updates += [(baseline_time, baseline_time * 0.9 + 0.1 * opt_outs['masked_cost'].mean())]\n",
    "    hard_attn_updates += opt_outs['attn_updates']\n",
    "    \n",
    "f_alpha = theano.function(inps, alphas, name='f_alpha', updates=hard_attn_updates)\n",
    "if options['selector']:\n",
    "    f_sels = theano.function(inps, opt_outs['selector'], name='f_sels', updates=hard_attn_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from IPython import embed\n",
    "def gen_sample(tparams, f_init, f_next, ctx0, options,\n",
    "               trng=None, k=1, maxlen=30, stochastic=False):\n",
    "    \"\"\"Generate captions with beam search.\n",
    "    \n",
    "    This function uses the beam search algorithm to conditionally\n",
    "    generate candidate captions. Supports beamsearch and stochastic\n",
    "    sampling.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tparams : OrderedDict()\n",
    "        dictionary of theano shared variables represented weight\n",
    "        matricies\n",
    "    f_init : theano function\n",
    "        input: annotation, output: initial lstm state and memory \n",
    "        (also performs transformation on ctx0 if using lstm_encoder)\n",
    "    f_next: theano function\n",
    "        takes the previous word/state/memory + ctx0 and runs one\n",
    "        step through the lstm\n",
    "    ctx0 : numpy array\n",
    "        annotation from convnet, of dimension #annotations x # dimension\n",
    "        [e.g (196 x 512)]\n",
    "    options : dict\n",
    "        dictionary of flags and options\n",
    "    trng : random number generator\n",
    "    k : int\n",
    "        size of beam search\n",
    "    maxlen : int\n",
    "        maximum allowed caption size\n",
    "    stochastic : bool\n",
    "        if True, sample stochastically \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sample : list of list\n",
    "        each sublist contains an (encoded) sample from the model \n",
    "    sample_score : numpy array\n",
    "        scores of each sample\n",
    "    \"\"\"\n",
    "    if k > 1:\n",
    "        assert not stochastic, 'Beam search does not support stochastic sampling'\n",
    "\n",
    "    sample = []\n",
    "    sample_score = []\n",
    "    if stochastic:\n",
    "        sample_score = 0\n",
    "\n",
    "    live_k = 1\n",
    "    dead_k = 0\n",
    "\n",
    "    hyp_samples = [[]] * live_k\n",
    "    hyp_scores = numpy.zeros(live_k).astype('float32')\n",
    "    hyp_states = []\n",
    "    hyp_memories = []\n",
    "\n",
    "    # only matters if we use lstm encoder\n",
    "    rval = f_init(ctx0)\n",
    "    ctx0 = rval[0]\n",
    "    next_state = []\n",
    "    next_memory = []\n",
    "    # the states are returned as a: (dim,) and this is just a reshape to (1, dim)\n",
    "    for lidx in xrange(options['n_layers_lstm']):\n",
    "        next_state.append(rval[1+lidx])\n",
    "        next_state[-1] = next_state[-1].reshape([1, next_state[-1].shape[0]])\n",
    "    for lidx in xrange(options['n_layers_lstm']):\n",
    "        next_memory.append(rval[1+options['n_layers_lstm']+lidx])\n",
    "        next_memory[-1] = next_memory[-1].reshape([1, next_memory[-1].shape[0]])\n",
    "    # reminder: if next_w = -1, the switch statement\n",
    "    # in build_sampler is triggered -> (empty word embeddings)  \n",
    "    next_w = -1 * numpy.ones((1,)).astype('int64')\n",
    "\n",
    "    for ii in xrange(maxlen):\n",
    "        # our \"next\" state/memory in our previous step is now our \"initial\" state and memory\n",
    "        rval = f_next(*([next_w, ctx0]+next_state+next_memory))\n",
    "        next_p = rval[0]\n",
    "        next_w = rval[1]\n",
    "\n",
    "        # extract all the states and memories\n",
    "        next_state = []\n",
    "        next_memory = []\n",
    "        for lidx in xrange(options['n_layers_lstm']):\n",
    "            next_state.append(rval[2+lidx])\n",
    "            next_memory.append(rval[2+options['n_layers_lstm']+lidx])\n",
    "\n",
    "        if stochastic:\n",
    "            sample.append(next_w[0]) # if we are using stochastic sampling this easy\n",
    "            sample_score += next_p[0,next_w[0]]\n",
    "            if next_w[0] == 0:\n",
    "                break\n",
    "        else:\n",
    "            cand_scores = hyp_scores[:,None] - numpy.log(next_p) \n",
    "            cand_flat = cand_scores.flatten()\n",
    "            ranks_flat = cand_flat.argsort()[:(k-dead_k)] # (k-dead_k) numpy array of with min nll\n",
    "            \n",
    "            voc_size = next_p.shape[1]\n",
    "            # indexing into the correct selected captions\n",
    "            trans_indices = ranks_flat / voc_size\n",
    "            word_indices = ranks_flat % voc_size\n",
    "            costs = cand_flat[ranks_flat] # extract costs from top hypothesis\n",
    "\n",
    "            # a bunch of lists to hold future hypothesis\n",
    "            new_hyp_samples = []\n",
    "            new_hyp_scores = numpy.zeros(k-dead_k).astype('float32')\n",
    "            new_hyp_states = []\n",
    "            for lidx in xrange(options['n_layers_lstm']):\n",
    "                new_hyp_states.append([])\n",
    "            new_hyp_memories = []\n",
    "            for lidx in xrange(options['n_layers_lstm']):\n",
    "                new_hyp_memories.append([])\n",
    "\n",
    "            # get the corresponding hypothesis and append the predicted word\n",
    "            for idx, [ti, wi] in enumerate(zip(trans_indices, word_indices)):\n",
    "                new_hyp_samples.append(hyp_samples[ti]+[wi])\n",
    "                new_hyp_scores[idx] = copy.copy(costs[ti]) # copy in the cost of that hypothesis \n",
    "                for lidx in xrange(options['n_layers_lstm']):\n",
    "                    new_hyp_states[lidx].append(copy.copy(next_state[lidx][ti]))\n",
    "                for lidx in xrange(options['n_layers_lstm']):\n",
    "                    new_hyp_memories[lidx].append(copy.copy(next_memory[lidx][ti]))\n",
    "            \n",
    "            # check the finished samples for <eos> character\n",
    "            new_live_k = 0\n",
    "            hyp_samples = []\n",
    "            hyp_scores = []\n",
    "            hyp_states = []\n",
    "            for lidx in xrange(options['n_layers_lstm']):\n",
    "                hyp_states.append([])\n",
    "            hyp_memories = []\n",
    "            for lidx in xrange(options['n_layers_lstm']):\n",
    "                hyp_memories.append([])\n",
    "\n",
    "            for idx in xrange(len(new_hyp_samples)):\n",
    "                if new_hyp_samples[idx][-1] == 0:\n",
    "                    print new_hyp_samples[idx]\n",
    "                    sample.append(new_hyp_samples[idx])\n",
    "                    sample_score.append(new_hyp_scores[idx])\n",
    "                    dead_k += 1 # completed sample!\n",
    "                else:\n",
    "                    new_live_k += 1 # collect collect correct states/memories\n",
    "                   # print new_hyp_samples[idx]\n",
    "                    hyp_samples.append(new_hyp_samples[idx])\n",
    "                    hyp_scores.append(new_hyp_scores[idx])\n",
    "                    for lidx in xrange(options['n_layers_lstm']):\n",
    "                        hyp_states[lidx].append(new_hyp_states[lidx][idx])\n",
    "                    for lidx in xrange(options['n_layers_lstm']):\n",
    "                        hyp_memories[lidx].append(new_hyp_memories[lidx][idx])\n",
    "            hyp_scores = numpy.array(hyp_scores)\n",
    "            live_k = new_live_k\n",
    "\n",
    "            if new_live_k < 1:\n",
    "                break\n",
    "            if dead_k >= k:\n",
    "                break\n",
    "\n",
    "            next_w = numpy.array([w[-1] for w in hyp_samples])\n",
    "            next_state = []\n",
    "            for lidx in xrange(options['n_layers_lstm']):\n",
    "                next_state.append(numpy.array(hyp_states[lidx]))\n",
    "            next_memory = []\n",
    "            for lidx in xrange(options['n_layers_lstm']):\n",
    "                next_memory.append(numpy.array(hyp_memories[lidx]))\n",
    "\n",
    "    if not stochastic:\n",
    "        # dump every remaining one\n",
    "        if live_k > 0:\n",
    "            for idx in xrange(live_k):\n",
    "                sample.append(hyp_samples[idx])\n",
    "                sample_score.append(hyp_scores[idx])\n",
    "\n",
    "    return sample, sample_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Caption and Attention Visualization\n",
    "\n",
    "(The next five cells can be run over and over to visualize a random image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = numpy.random.randint(0, len(valid[0])) # random image\n",
    "k = 1 # beam width\n",
    "use_gt = False # set to False if you want to use the generated sample\n",
    "gt = valid[0][idx][0] # groundtruth\n",
    "context = numpy.array(valid[1][valid[0][idx][1]].todense()).reshape([14*14, 512]) # annotation\n",
    "img = LoadImage(image_path+flist[valid[0][idx][1]])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 20, 139, 295, 7, 6, 52, 0]\n",
      "[64, 10, 2, 162, 26, 10, 712, 7, 6, 52, 0]\n",
      "[64, 10, 2, 162, 26, 10, 712, 4, 6, 52, 0]\n",
      "[64, 20, 139, 295, 4, 6, 52, 39, 6, 84, 3, 0]\n",
      "[64, 10, 2, 162, 7, 6, 52, 39, 2, 70, 3, 0]\n",
      "[64, 20, 139, 295, 4, 6, 52, 39, 6, 271, 3, 0]\n",
      "[64, 10, 2, 162, 7, 6, 52, 21, 12, 2, 70, 3, 0]\n",
      "[64, 10, 2, 162, 7, 6, 52, 21, 12, 2, 1586, 3, 0]\n",
      "[64, 10, 2, 162, 7, 6, 52, 21, 12, 2, 344, 3, 0]\n",
      "[64, 10, 2, 162, 7, 6, 52, 21, 12, 2, 30, 70, 3, 0]\n"
     ]
    }
   ],
   "source": [
    "if not use_gt:\n",
    "    sample, score = gen_sample(tparams, f_init, f_next, context, \n",
    "                                      options, trng=trng, k=10, maxlen=200, stochastic=False)\n",
    "    sidx = numpy.argmin(score)\n",
    "    caption = sample[sidx][:-1]\n",
    "    #print sidx\n",
    "    for c in sample:\n",
    "        words = map(lambda w: word_idict[w] if w in word_idict else '<UNK>', c[:-1])\n",
    "        #print ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO_val2014_000000262509.jpg\n",
      "Sample: there are many boats in the water\n",
      "GT: a city scene that was seen from the other side of a river .\n"
     ]
    }
   ],
   "source": [
    "# print the generated caption and the ground truth\n",
    "print flist[valid[0][idx][1]]\n",
    "if use_gt:\n",
    "    caption = map(lambda w: worddict[w] if worddict[w] < options['n_words'] else 1, gt.split())\n",
    "words = map(lambda w: word_idict[w] if w in word_idict else '<UNK>', caption)\n",
    "print 'Sample:', ' '.join(words)\n",
    "print 'GT:', gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# alpha = f_alpha(numpy.array(caption).reshape(len(caption),1), \n",
    "                numpy.ones((len(caption),1), dtype='float32'), \n",
    "                context.reshape(1,context.shape[0],context.shape[1]))\n",
    "if options['selector']:\n",
    "    sels = f_sels(numpy.array(caption).reshape(len(caption),1), \n",
    "                   numpy.ones((len(caption),1), dtype='float32'), \n",
    "                   context.reshape(1,context.shape[0],context.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the Visualization   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display the visualization\n",
    "n_words = alpha.shape[0] + 1\n",
    "w = numpy.round(numpy.sqrt(n_words))\n",
    "h = numpy.ceil(numpy.float32(n_words) / w)\n",
    "        \n",
    "plt.subplot(w, h, 1)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "\n",
    "smooth = True\n",
    "\n",
    "for ii in xrange(alpha.shape[0]):\n",
    "    plt.subplot(w, h, ii+2)\n",
    "    lab = words[ii]\n",
    "    if options['selector']:\n",
    "        lab += '(%0.2f)'%sels[ii]\n",
    "    plt.text(0, 1, lab, backgroundcolor='white', fontsize=13)\n",
    "    plt.text(0, 1, lab, color='black' if sels[ii] > 0.1 else 'red', fontsize=13)\n",
    "    plt.imshow(img)\n",
    "    if smooth:\n",
    "        alpha_img = skimage.transform.pyramid_expand(alpha[ii,0,:].reshape(14,14), upscale=16, sigma=20)\n",
    "    else:\n",
    "        alpha_img = skimage.transform.resize(alpha[ii,0,:].reshape(14,14), [img.shape[0], img.shape[1]])\n",
    "    plt.imshow(alpha_img, alpha=0.8)\n",
    "    plt.set_cmap(cm.Greys_r)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
